{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Embedding, Lambda,Dropout,Conv1D,Activation, Dense, Bidirectional,GlobalMaxPooling1D, LSTM, SpatialDropout1D, TimeDistributed,Masking,Layer\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.get_default_graph\n",
    "from keras.layers.merge import add\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS)) \n",
    "SYMBOLCHARS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "OffensiveLangDF = pd.read_csv('../Data/Offensive Language Dataset/Cleaned_labeled_data.csv')\n",
    "spamSmsDF = pd.read_csv('../Data/SMS Spam Dataset/Cleaned_SMSSpamCollection.csv')\n",
    "politicalDF = pd.read_csv('../Data/Indian Political Tweets Dataset/cleaned-tweets.csv')\n",
    "\n",
    "currentDF = politicalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeText(textData):\n",
    "\n",
    "    textData = textData.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    textData = textData.lower()\n",
    "    tokens = parser(textData)\n",
    "\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    \n",
    "    # Remove Stop Words\n",
    "    tokens = [tok for tok in tokens if tok.lower() not in STOPWORDS]\n",
    "    # Remove Symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLCHARS]\n",
    "    # Remove words with less than 3 characters\n",
    "    tokens = [tok for tok in tokens if len(tok) >= 3]\n",
    "    # Remove Non-Alphabetic Characters\n",
    "    tokens = [tok for tok in tokens if tok.isalpha()]\n",
    "    \n",
    "    # Stemming of Words\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(word) for word in tokens]\n",
    "    \n",
    "    tokens = list(set(tokens))\n",
    "    textData = ' '.join(tokens[:])\n",
    "    return textData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDF['text'] = currentDF['text'].apply(lambda x:tokenizeText(x))\n",
    "y = list(currentDF['category'])\n",
    "x = list(currentDF['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10205\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(num_words=1000)\n",
    "token.fit_on_texts(x)\n",
    "vocab_size = len(token.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "# for cnn preproces\n",
    "cnn_texts_seq = token.texts_to_sequences(x)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(np.asarray(cnn_texts_mat), np.asarray(y_enc), test_size=0.2, random_state=42)\n",
    "# split the dataset into training and validation datasets\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3878, 100), (1212, 100), (970, 100))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,x_train,y_train,x_val,y_val,filepath):\n",
    "        # checkpoint\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "        callbacks_list = [checkpoint]\n",
    "        history = model.fit(x_train, y_train,validation_data=(x_val,y_val),callbacks=callbacks_list,epochs=10, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,x_test,file_path):\n",
    "    model.load_weights(file_path)  \n",
    "    predicts = model.predict(x_test, batch_size=2)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 50)           510250    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 537,068\n",
      "Trainable params: 537,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1935/1939 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9088\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93812, saving model to ./cnn_model_v2.hdf5\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.2107 - accuracy: 0.9087 - val_loss: 0.1601 - val_accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "1932/1939 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9570\n",
      "Epoch 00002: val_accuracy improved from 0.93812 to 0.94389, saving model to ./cnn_model_v2.hdf5\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.1082 - accuracy: 0.9564 - val_loss: 0.1514 - val_accuracy: 0.9439\n",
      "Epoch 3/10\n",
      "1932/1939 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9666\n",
      "Epoch 00003: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.0799 - accuracy: 0.9665 - val_loss: 0.2210 - val_accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "1929/1939 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9717\n",
      "Epoch 00004: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 8s 4ms/step - loss: 0.0716 - accuracy: 0.9719 - val_loss: 0.2074 - val_accuracy: 0.9332\n",
      "Epoch 5/10\n",
      "1934/1939 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9741\n",
      "Epoch 00005: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 4ms/step - loss: 0.0626 - accuracy: 0.9740 - val_loss: 0.2647 - val_accuracy: 0.9398\n",
      "Epoch 6/10\n",
      "1927/1939 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9764\n",
      "Epoch 00006: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 10s 5ms/step - loss: 0.0582 - accuracy: 0.9765 - val_loss: 0.3048 - val_accuracy: 0.9315\n",
      "Epoch 7/10\n",
      "1935/1939 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9760\n",
      "Epoch 00007: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.0533 - accuracy: 0.9760 - val_loss: 0.3165 - val_accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "1935/1939 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9757\n",
      "Epoch 00008: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 4ms/step - loss: 0.0527 - accuracy: 0.9755 - val_loss: 0.3256 - val_accuracy: 0.9381\n",
      "Epoch 9/10\n",
      "1932/1939 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9775\n",
      "Epoch 00009: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.0535 - accuracy: 0.9776 - val_loss: 0.3491 - val_accuracy: 0.9398\n",
      "Epoch 10/10\n",
      "1931/1939 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9754\n",
      "Epoch 00010: val_accuracy did not improve from 0.94389\n",
      "1939/1939 [==============================] - 9s 5ms/step - loss: 0.0539 - accuracy: 0.9755 - val_loss: 0.5563 - val_accuracy: 0.9249\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v2(): \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,\n",
    "                        50, \n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_v2 = get_cnn_model_v2()\n",
    "train_model(model_v2,x_train,y_train,x_val,y_val,'./cnnModel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = test_model(model_v2,x_test,'./cnnModel.hdf5')\n",
    "y_test_dec = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294  19]\n",
      " [ 44 613]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOTPOL       0.87      0.94      0.90       313\n",
      "         POL       0.97      0.93      0.95       657\n",
      "\n",
      "    accuracy                           0.94       970\n",
      "   macro avg       0.92      0.94      0.93       970\n",
      "weighted avg       0.94      0.94      0.94       970\n",
      "\n",
      "Accuracy: 0.9350515463917526\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test_dec, y_preds))\n",
    "print(metrics.classification_report(y_test_dec, y_preds))\n",
    "print(\"Accuracy:\",accuracy_score(y_test_dec,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
