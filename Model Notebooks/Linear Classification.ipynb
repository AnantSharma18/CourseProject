{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import spacy\n",
    "import string\n",
    "import joblib\n",
    "from spacy.lang.en import English\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "spacy.load('en')\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS)) \n",
    "SYMBOLCHARS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OffensiveLangDF = pd.read_csv('../Data/Offensive Language Dataset/Cleaned_labeled_data.csv')\n",
    "spamSmsDF = pd.read_csv('../Data/SMS Spam Dataset/Cleaned_SMSSpamCollection.csv')\n",
    "politicalDF = pd.read_csv('../Data/Indian Political Tweets Dataset/cleaned-tweets.csv')\n",
    "\n",
    "currentDF = politicalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeText(textData):\n",
    "\n",
    "    textData = textData.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    textData = textData.lower()\n",
    "    tokens = parser(textData)\n",
    "\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    \n",
    "    # Remove Stop Words\n",
    "    tokens = [tok for tok in tokens if tok.lower() not in STOPWORDS]\n",
    "    # Remove Symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLCHARS]\n",
    "    # Remove words with less than 3 characters\n",
    "    tokens = [tok for tok in tokens if len(tok) >= 3]\n",
    "    # Remove Non-Alphabetic Characters\n",
    "    tokens = [tok for tok in tokens if tok.isalpha()]\n",
    "    \n",
    "    # Stemming of Words\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(word) for word in tokens]\n",
    "    \n",
    "    tokens = list(set(tokens))\n",
    "    textData = ' '.join(tokens[:])\n",
    "    return textData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hateSpeechDF['text'] = hateSpeechDF['text'].apply(lambda x:tokenizeText(x))\n",
    "currentDF['text'] = currentDF['text'].apply(lambda x:tokenizeText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4627    aiadmk nda parti ganga india join corrupt like...\n",
      "3777    nitish son remarriag quickest rage bjp oath bi...\n",
      "4924    upa india btw take aspir monument social prote...\n",
      "3770    sushmaswaraj politician congratul pic visit in...\n",
      "510                            sim unlock tmo instal card\n",
      "                              ...                        \n",
      "1539    time lol fhe jessica good decent emma gossip a...\n",
      "3029    bjpempowersdalit peopl chat empow today india ...\n",
      "2604        trade includ itali paologentiloni talk promot\n",
      "426     sleep confus hour serious clock today turn loo...\n",
      "3590    announc presid complex dharna tuesday sonia pa...\n",
      "Name: text, Length: 4545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(currentDF['text'], currentDF['category'])\n",
    "print (train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction for Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vector as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(currentDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 10204)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(currentDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(currentDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(currentDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.classification_report(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Classification Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier | Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOTPOL       0.98      0.86      0.92       574\n",
      "         POL       0.92      0.99      0.96       941\n",
      "\n",
      "    accuracy                           0.94      1515\n",
      "   macro avg       0.95      0.93      0.94      1515\n",
      "weighted avg       0.95      0.94      0.94      1515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_count, train_y, xvalid_count)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier | Word level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOTPOL       0.96      0.90      0.93       540\n",
      "         POL       0.95      0.98      0.96       975\n",
      "\n",
      "    accuracy                           0.95      1515\n",
      "   macro avg       0.96      0.94      0.95      1515\n",
      "weighted avg       0.95      0.95      0.95      1515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier | N-Gram level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOTPOL       0.08      0.93      0.15        45\n",
      "         POL       1.00      0.69      0.81      1470\n",
      "\n",
      "    accuracy                           0.69      1515\n",
      "   macro avg       0.54      0.81      0.48      1515\n",
      "weighted avg       0.97      0.69      0.79      1515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier | Character level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOTPOL       0.92      0.88      0.90       526\n",
      "         POL       0.94      0.96      0.95       989\n",
      "\n",
      "    accuracy                           0.93      1515\n",
      "   macro avg       0.93      0.92      0.92      1515\n",
      "weighted avg       0.93      0.93      0.93      1515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(vectorizer,classifier,train_data,train_labels,test_data,test_label,pickle_name):\n",
    "    # Initialize Pipeline\n",
    "    vec_clf = Pipeline([('vectorizer', vectorizer), ('pac', classifier)])\n",
    "    # fit the training dataset on the classifier\n",
    "    vec_clf.fit(train_data,train_labels)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = vec_clf.predict(test_data)\n",
    "    print(metrics.accuracy_score(predictions, test_label))\n",
    "    # save Pipline\n",
    "    joblib.dump(vec_clf, pickle_name, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9498349834983498\n"
     ]
    }
   ],
   "source": [
    "save_model(tfidf_vect,linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000),train_x,train_y,valid_x,valid_y,'../Saved Model/LR_Pol.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POL' 'NOTPOL']\n"
     ]
    }
   ],
   "source": [
    "classifier = joblib.load('../Saved Model/LR_Pol.pkl')\n",
    "tweet = [\"What is BJP doing for Farmers\", \"Hello how are you\"]\n",
    "predict = classifier.predict(tweet)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
